<!DOCTYPE html><html><head>  <meta  content="text/html; charset=utf-8"  http-equiv="content-type">  <meta  http-equiv="X-UA-Compatible"  content="chrome=1">  <title>Miguelao.GitHub.io by miguelao</title>  <link  rel="stylesheet"  href="stylesheets/styles.css">  <link  rel="stylesheet"  href="stylesheets/github-dark.css">  <script  src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>  <script  src="javascripts/respond.js"></script>  <!--[if lt IE 9]>    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->  <!--[if lt IE 8]>  <link rel="stylesheet" href="stylesheets/ie.css">    <![endif]-->  <meta  name="viewport"  content="width=device-width, initial-scale=1, user-scalable=no"></head><body>  <div  id="header">    <nav>      <li  class="fork"><a  href="https://github.com/miguelao">View On GitHub</a></li>    </nav>  </div>  <!-- end header --><div  style="width: 778px;"  class="wrapper"><section>  <div  id="title">    <h1>Miguelao.GitHub.io</h1>    <p>I can haz website?</p>  </div>  <h3> <a  id="welcome-to-github-pages"  class="anchor"  href="#welcome-to-github-pages"       aria-hidden="true"><span         class="octicon octicon-link"></span></a>    Welcome to my GitHub Page</h3>  <p>I'm a Chrome developer working in all things related to Media Input/Capture/Recording (which obliquely relates to <strong>WebRtc</strong> <img  style="width: 19px; height: 19px;"  src="https://avatars0.githubusercontent.com/u/10526312?v=3&s=400">related things. I have a mixed background in signal processing, embedded/Real-Time systems, and basically all kinds of software plumbings.</p>  <h3><span  style="color: rgb(240, 231, 213);"><i>Le</i> What? Media Capture and the Web</span></h3>  <p>I've spent a few years trying to improve the state of media capture, recording and manipulation on the web. Why? Let's look at early 2015, most browsers have some spotty support to capture media via a number of ways; I say "some browsers" because in this aspect Firefox was in a better situation, with Chrome having worked only around PeerConnection-related goals and the rest in some pathetical caveman-like state. We needed to start being leaders <i>pronto</i> and we also needed strong Specs to send signals to the laggards to start catching up.</p>  <p> From Chrome I've been trying to improve this situation, by constructing bridges between content sources and sinks, the online and offline worlds, all of them coalescing around the <code>MediaStream(Track)</code> abstraction: essentially tending to the arrows in the following diagram of JavaScript classes, their potential connections and associated standards:</p> <img src="http://i66.tinypic.com/lxg8m.png"/>  <p>Chrome in 2015 supported the arrows marked in black and orange, which give some options but are very limited:  <ol>  <li><code>getUserMedia()</code>: allows for capturing live video/audio but provides no access to the data, its timing information  or its metadata; needs a sink (<code>&lt;video/audio></code>) which essentially provides no access to any of that information either.</li>  <li>passing data through a <code>&lt;video></code> and then through a <code>&lt;canvas></code> to download the pixels via its 2D/3D context (WebGL), incurs in tremendous time and CPU penalties due to the round trip(s) to the GPU.</li>  <li><code>WebAudio</code>: tremendously flexible, but can't record, and is only good for, well, audio.</li>  <li><code>&lt;input capture></code>, which is not in the diagram, is widely implemented on mobile devices, just dumps you to the system capture/image picker</li>  </ol>  </p>  <p> So I started working on the Red, Green and Blue arrows. The biggest win is Media Recorder (red arrow), because it allows transforming online live content into offline content, simply put. This is <b>huge</b> because it makes use cases such as gaming (think Twitch, YouTube Live), cam apps (Snapchat, Instagram), screencasts, <i>broadcasting</i> etc feasible on the Web. (I say feasible because without this API it might be <i>possible</i>, but frankly, it would be slow as hell and inviable for things like, having users beyond your dormmates). Developers, that know a lot about their businesses, requested this feature en-masse: the <a target="_blank"  href="https://code.google.com/p/chromium/issues/detail?id=262211">original bug tracker in Chrome</a> was the most starred feature ever in Chromium yet it had been dangling with no one really doing anything about it. Why? Well, mostly because it's fecking hard to write code for Real-Time media encoding, <i>and</i> is hard to get Specs right; takes a thick skin to make any progress in any of those two realms, let alone in both. Also  Org-wise this was internally ascribed to the Cr-WebRTC realm for the simple reason that the Spec stems from the <a href="https://www.w3.org/2011/04/webrtc/">WebRTC W3C working group</a>, but it was down-prioritized in favour of the black and orange arrows.</p>  <p>MediaRecorder work started in the second half of 2015, was shipped in M47 and has been still active due to the hardware encoders that also needed to be carefully wired (because they crash and they take down the whole browser, which is a no-no). But wait! Wouldn't it be cool to be able to record videos as they play back, or my latest cool WebGL game? Yeah, that's why emircan@chromium.org and I landed <a  target="_blank"  href="http://w3c.github.io/mediacapture-fromelement/">stream capture from &lt;canvas/video/audio&gt; elements</a> in Chrome, which allows you to plug those elements into a MediaRecorder. Boom! Building blocks that come together!</p>  <p>The next missing item was how to take pictures with full resolution and manipulate the photo-specific settings (think zoom, or flash), which, surprise surprise, were not surfaced to the Web <i>at all</i> before. This is the <a href="https://w3c.github.io/mediacapture-image/">W3C Image Capture Spec</a> and it has been implemented and shipped as an experiment in M56-57-58, so we're collecting data to ship it fully.</p>  <h3><span  style="color: rgb(240, 231, 213);">Life before all that</span></h3>  <p>Yeah I did do interesting stuff before joining G (I guess previous    employers wouldn't be thrilled if I was to give too many details so    I'll keep it fuzzy). My previous employer was Alcatel-Lucent-Bell Labs    in Antwerpen, Belgium, same place were (mostly) the same guys    developed and shipped a bazillion DSL boxes giving service to a ton of    homes all around the world. In particular I worked in the DSL    aggregator IP (the whole thing is marketed as <a  target="_blank"  href="https://www.alcatel-lucent.com/products/7360-isam-fx">ISAM</a>)    which is the secret sauce of where all DSL or PON customer lines get    bundled into a massive chunk of uplinks of about ~500GBps (usually    splitted into a number of 10/40 or even 100GB ethernet over fiber).    ALu is a great place to do network equipment and, well, not too good a    place for anything else.</p>  <p>Also in Belgium (with trips to Noordwijk in the Netherlands) I worked    for this contractor of the European Space Agency that got me to deal    with two systems; one was a <a  target="_blank"  href="http://www.spaceapplications.com/products/neuroscience/view">VR      for astronaut experiments</a>, measuring the response time to    different audiovisual stimuli, where I did the real time parts    (basically a pace maker sucking managing FIFOs for sensor inputs and    actuator outputs, all using RTX for Win - sig).&nbsp; The other    project was an <a  target="_blank"  href="https://www.esa.int/gsp/ACT/doc/EVENTS/bmiworkshop/ACT-PRE-BNG-WEAR%28BMI_Workshop%29.pdf">attitude      and heading tracking to support astronauts onboard the ISS</a> (this    one eventually <a  target="_blank"  href="http://www.esa.int/Our_Activities/Space_Engineering_Technology/Augmented_reality_to_help_astronauts_make_sense_of_space">made      it up there</a>!); in here I did the Kalman filter formulation for    all sensor integration (those days accelerometers and gyros were not    integrated and was quite a challenge to solder them, let alone model    it).</p>  <p>Immediately before that I worked in Spain for a few years in Real    Time Linux systems for trains, more concretely for train-ground    communication and a bit on train controllers. That was a ton of fun,    dealing with those tiny RTAIs (later Xenomais) bridging GRPS and GSMR    to the MVB (a Real-Time serial bus on the train from where all systems    hang, including engines and brakes!). Moreover it's heart warming to    see those systems in operation all around the world carrying tiny    pieces of me :)</p>  <p>Even before that I finished a M.Sc. in CompSci in UCD (Ireland) on    power consumption estimation for software running on embedded devices,    which was a quite interesting research that lead to a few publications    here and there. </p></section>  <div>    <hr> <span  class="credits left">Project maintained by <a  href="https://github.com/miguelao">miguelao</a></span>    <span  class="credits right">Hosted on GitHub Pages â€” Theme by <a  href="https://twitter.com/michigangraham">mattgraham</a></span>  </div></div>  <!--[if !IE]><script>fixScale(document);</script><![endif]--></body></html>